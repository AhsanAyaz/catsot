---
phase: 01-foundation
plan: 05
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - modules/05-grounding-search/README.md
  - modules/05-grounding-search/demonstration.md
  - modules/05-grounding-search/exercise.md
  - modules/05-grounding-search/solutions/solution.md
autonomous: true

must_haves:
  truths:
    - "Demonstration shows grounding toggle in AI Studio"
    - "Participants understand grounding provides real-time web information"
    - "Exercise shows side-by-side comparison (with/without grounding)"
    - "Grounding metadata structure is explained (chunks, supports, citations)"
  artifacts:
    - path: "modules/05-grounding-search/README.md"
      provides: "Module overview for grounding with Google Search"
      min_lines: 20
    - path: "modules/05-grounding-search/demonstration.md"
      provides: "Grounding toggle and metadata demonstration"
      min_lines: 40
    - path: "modules/05-grounding-search/solutions/solution.md"
      provides: "Example prompts with grounding metadata"
      min_lines: 35
  key_links:
    - from: "modules/05-grounding-search/demonstration.md"
      to: "AI Studio grounding toggle"
      via: "Tools panel configuration"
      pattern: "Tools.*Google Search"
    - from: "modules/05-grounding-search/solutions/solution.md"
      to: "grounding metadata"
      via: "shows groundingChunks and groundingSupports structure"
      pattern: "groundingMetadata"
---

<objective>
Create Module 05: Grounding with Google Search - teaching participants how to augment Gemini responses with real-time web information and understand citation metadata.

Purpose: Grounding solves the knowledge cutoff problem and enables fact-checking with sources. This module shows the official alternative to manual RAG implementation and prepares participants for building apps that need current information.

Output: Complete module with demonstration of AI Studio's grounding toggle, hands-on exercise comparing grounded vs non-grounded responses, and solutions explaining metadata structure.
</objective>

<execution_context>
@/home/ahsan/.claude/get-shit-done/workflows/execute-plan.md
@/home/ahsan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@/home/ahsan/projects/code-at-speed-of-thought/.planning/PROJECT.md
@/home/ahsan/projects/code-at-speed-of-thought/.planning/ROADMAP.md
@/home/ahsan/projects/code-at-speed-of-thought/.planning/STATE.md
@/home/ahsan/projects/code-at-speed-of-thought/.planning/phases/01-foundation/01-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Create Module 05 structure and README with grounding overview</name>
  <files>
    modules/05-grounding-search/README.md
    modules/05-grounding-search/solutions/.gitkeep
  </files>
  <action>
Create module directory structure and README explaining grounding with Google Search.

**README.md content:**
- Module title: "Module 05: Grounding with Google Search"
- Duration: 20 minutes
- Learning Objectives:
  * Understand what grounding is and why it matters (real-time information, fact-checking)
  * Enable grounding in AI Studio using the Google Search tool
  * Interpret grounding metadata (groundingChunks, groundingSupports, citations)
  * Recognize when grounding is appropriate vs when it's not needed
- Prerequisites:
  * Completion of Module 01 (AI Studio basics)
  * Understanding of LLM knowledge cutoff limitations
- Overview explaining the problem and solution:
  * **The problem:** LLMs have knowledge cutoff dates (training data only up to certain date)
  * **Old approach:** Manual RAG (Retrieval Augmented Generation) with web scraping
  * **New approach:** Gemini's built-in grounding with Google Search
  * **How it works:** Model decides whether to search based on prompt, synthesizes results with citations
- Key concepts to introduce:
  * **Automatic decision:** Gemini determines whether web search is needed
  * **Citation metadata:** groundingChunks (sources), groundingSupports (which text came from which source)
  * **Not always triggered:** Simple factual queries may not need grounding if within training data
- Reference to demonstration.md, exercise.md
- Note from RESEARCH.md about AI Studio free tier for testing (vs paid API usage)
  </action>
  <verify>
Verify README exists and covers key concepts:

```bash
cat modules/05-grounding-search/README.md | grep -i "grounding" | wc -l
```
Expected: At least 5 mentions

Verify knowledge cutoff problem is explained:
```bash
cat modules/05-grounding-search/README.md | grep -iE "(cutoff|real-time|current)" | wc -l
```
Expected: At least 3 mentions

Verify learning objectives exist:
```bash
cat modules/05-grounding-search/README.md | grep -i "learning objective" -A 5 | wc -l
```
Expected: At least 4 lines
  </verify>
  <done>
Module 05 structure exists with README containing learning objectives, explanation of grounding vs RAG, overview of how automatic grounding works, and key concepts about metadata structure.
  </done>
</task>

<task type="auto">
  <name>Create demonstration showing AI Studio grounding toggle and metadata</name>
  <files>modules/05-grounding-search/demonstration.md</files>
  <action>
Create instructor demonstration guide showing AI Studio's grounding feature, following RESEARCH.md patterns and avoiding pitfalls.

**Content structure (5-7 minute demonstration):**

**Introduction (1 minute):**
- The knowledge cutoff problem: "Who won Euro 2024?" (event after training cutoff)
- Traditional solution: Build RAG pipeline with web scraping
- Gemini solution: Built-in grounding with Google Search
- This is production-ready, not a hack

**Step-by-step demonstration (5-6 minutes):**

1. **Baseline: Without grounding**
   - Action: Create new prompt in AI Studio
   - Action: Enter: "Who won Euro 2024?"
   - Action: Run (with grounding OFF)
   - Expected result: Generic response or "I don't have information about events after my training cutoff"
   - Point out: Model is correctly indicating uncertainty
   - [Screenshot: Non-grounded response]

2. **Enable grounding**
   - Action: Click "Tools" panel (right side of interface)
   - Expected result: Tools options appear
   - Action: Toggle "Google Search grounding" to ON
   - Expected result: Grounding enabled indicator appears
   - [Screenshot: Tools panel with grounding enabled]

3. **Same prompt with grounding**
   - Action: Run same prompt: "Who won Euro 2024?"
   - Expected result: Current, accurate answer with source citations
   - Point out:
     * Answer includes recent information (Spain won)
     * Response includes source attribution
     * Model synthesizes multiple sources automatically
   - [Screenshot: Grounded response with citations]

4. **Examine the metadata**
   - Action: In response panel, look for "Grounding" or metadata section
   - Show the structure (if visible in UI):
     * **webSearchQueries:** What search terms Gemini used
     * **groundingChunks:** List of sources (URLs, titles)
     * **groundingSupports:** Maps which text segments came from which sources
   - Point out: This metadata enables citation extraction in your app
   - [Screenshot: Grounding metadata panel]

5. **When grounding isn't triggered**
   - Action: Try prompt: "What is 2 + 2?"
   - Action: Run with grounding ON
   - Expected result: Direct answer, likely no web search
   - Point out: Gemini decides whether search is needed (simple math doesn't need it)
   - Explain: This saves costs and improves speed for queries that don't need current info

6. **Real-world grounding use case**
   - Action: Prompt: "What are the latest security vulnerabilities in React 18 as of January 2026?"
   - Action: Run with grounding ON
   - Expected result: Current security advisories with source links
   - Point out: Perfect for keeping docs current, fact-checking, research

**Key talking points:**
- **Automatic decision-making:** Model determines whether to search
- **Citation metadata:** Enables proper source attribution in your app
- **Not a replacement for everything:** Still need specialized data sources for proprietary info
- **Cost consideration:** Grounding costs more than non-grounded (see RESEARCH.md pricing)
- **Free in AI Studio:** Testing is free, production API has costs

**Common pitfall to address (from RESEARCH.md):**
- **Expectation:** "It should search for every prompt"
- **Reality:** Gemini only searches when needed (query requires current/specific info)
- **Solution:** Ask questions that genuinely need real-time data

**Metadata structure explanation:**
Show simplified example of grounding metadata (reference RESEARCH.md):
```json
{
  "groundingMetadata": {
    "webSearchQueries": ["euro 2024 winner"],
    "groundingChunks": [
      {
        "web": {
          "uri": "https://example.com/euro-2024-results",
          "title": "Euro 2024 Final Results"
        }
      }
    ],
    "groundingSupports": [
      {
        "segment": {
          "startIndex": 0,
          "endIndex": 25,
          "text": "Spain won Euro 2024..."
        },
        "groundingChunkIndices": [0],
        "confidenceScores": [0.98]
      }
    ]
  }
}
```
  </action>
  <verify>
Verify demonstration.md contains required sections:

```bash
cat modules/05-grounding-search/demonstration.md | grep -E "(Step [0-9]:|Action:|Expected result:|Screenshot:)" | wc -l
```
Expected: At least 18 matches

Verify metadata structure is explained:
```bash
cat modules/05-grounding-search/demonstration.md | grep -iE "(metadata|groundingChunk|groundingSupport)" | wc -l
```
Expected: At least 8 mentions

Verify pitfall is addressed:
```bash
cat modules/05-grounding-search/demonstration.md | grep -i "pitfall\|doesn't search\|not triggered" | wc -l
```
Expected: At least 2 mentions
  </verify>
  <done>
Demonstration guide exists with complete walkthrough showing grounding toggle in AI Studio, side-by-side comparison (with/without grounding), metadata structure explanation, and clarification of when grounding is/isn't triggered (addressing RESEARCH.md pitfall).
  </done>
</task>

<task type="auto">
  <name>Create hands-on exercise with grounding comparison tests</name>
  <files>
    modules/05-grounding-search/exercise.md
    modules/05-grounding-search/solutions/solution.md
  </files>
  <action>
Create hands-on exercise where participants test grounding with different query types.

**exercise.md content (10-13 minutes):**

**Your Task:**
Experiment with grounding to understand when it's useful and how to interpret grounding metadata.

**Setup (1 minute):**
1. Open aistudio.google.com
2. Create new prompt
3. Locate Tools panel (usually on right side)
4. Have grounding toggle ready to test ON/OFF

**Option A: Guided Challenge (For beginners)**

**Challenge:** Compare grounded vs non-grounded responses for different query types

Step 1: Current events test (3 minutes)
- Prompt: "What are the latest updates to the Gemini API in January 2026?"
- Run with grounding OFF
- Observe response (likely knowledge cutoff limitation)
- Enable grounding (Tools → Google Search grounding ON)
- Run same prompt
- Observe difference (current information with sources)
- Success criteria: You see citations and recent information

Step 2: Factual knowledge test (3 minutes)
- Prompt: "What is the capital of France?"
- Run with grounding ON
- Observe: Does it search? (May or may not - model decides)
- Prompt: "Who won the Nobel Prize in Physics in 2024?"
- Run with grounding ON
- Observe: Likely searches (recent event)
- Success criteria: You understand grounding is selective

Step 3: Examine metadata (3 minutes)
- For the Gemini API query (from Step 1), look for grounding metadata
- Try to identify:
  * Which sources were used? (look for URLs in response or metadata)
  * How many sources? (count citations)
  * What search terms did Gemini use? (if webSearchQueries visible)
- Success criteria: You can identify at least one source URL

Step 4: Test a domain-specific query (2 minutes)
- Prompt: "What is the current stock price of [pick a company]?"
- Run with grounding ON
- Observe: Real-time data with source
- Note: This shows grounding's value for dynamic data
- Success criteria: You get current information with attribution

**Option B: Independent Challenge (For advanced users)**

Goal: Design queries that benefit from grounding and queries that don't, then analyze the metadata structure.

Task ideas:
- Compare responses for "What is React?" (grounding OFF) vs "What are the latest React features?" (grounding ON)
- Test scientific queries: "Explain quantum computing" vs "Latest quantum computing breakthroughs in 2026"
- Try controversial topics and observe how grounding helps fact-check
- Extract citation information from grounding metadata

Requirements:
- Test at least 3 different query types
- Document which queries triggered web search and which didn't
- Identify patterns (current events vs timeless facts)
- Attempt to extract source URLs from metadata

Solution: See `solutions/solution.md` for reference

**For Fast Finishers: Going Further**

Advanced challenges:
- Combine grounding + structured output (e.g., "Get latest AI news as JSON")
- Test multi-step reasoning with grounding (e.g., "Compare GDP growth of France and Germany in 2025")
- Experiment with the API code export to see how grounding is configured
- Research the cost implications (see RESEARCH.md for pricing details)

**Success Criteria:**
- [ ] You have tested grounding with at least 3 different prompts
- [ ] You understand that grounding is automatic (model decides when to search)
- [ ] You can identify source citations in grounded responses
- [ ] You recognize when grounding adds value vs when it's unnecessary
- [ ] You are aware of grounding metadata structure

Duration: ⏱️ Expected: 11 minutes | Buffer: 3 minutes

**solutions/solution.md content:**

# Module 05 Solution

## Query Type Comparison

### Type 1: Current Events (Grounding Essential)

**Query:** "What are the latest updates to the Gemini API in January 2026?"

**Without Grounding:**
```
I don't have access to information about API updates in January 2026,
as my training data has a cutoff date. I recommend checking the official
Google AI documentation for the most current information.
```

**With Grounding:**
```
Recent updates to the Gemini API in January 2026 include:

1. **Gemini 3.0 Preview Release** - Introduces enhanced multimodal capabilities
   with improved image understanding and longer context windows (up to 2M tokens).
   [Source: Google AI Blog, Jan 15, 2026]

2. **Structured Output Enhancements** - Native support for Pydantic models and
   Zod schemas, simplifying schema definition for developers.
   [Source: Gemini API Documentation, Jan 20, 2026]

3. **Grounding Cost Reduction** - Pricing for grounded queries reduced from
   $35/1K to $25/1K queries for Gemini 3.x models.
   [Source: Google Cloud Pricing Updates, Jan 10, 2026]

For complete details, see: https://ai.google.dev/changelog
```

**Grounding Metadata Example:**
```json
{
  "groundingMetadata": {
    "webSearchQueries": [
      "Gemini API updates January 2026",
      "Google AI Gemini 3.0 release notes"
    ],
    "groundingChunks": [
      {
        "web": {
          "uri": "https://ai.google.dev/changelog",
          "title": "Gemini API Changelog - January 2026"
        }
      },
      {
        "web": {
          "uri": "https://cloud.google.com/blog/products/ai-machine-learning",
          "title": "Google Cloud AI Blog"
        }
      }
    ],
    "groundingSupports": [
      {
        "segment": {
          "startIndex": 54,
          "endIndex": 90,
          "text": "Gemini 3.0 Preview Release"
        },
        "groundingChunkIndices": [0],
        "confidenceScores": [0.95]
      }
    ]
  }
}
```

**Why grounding helps:** API updates are time-sensitive, beyond training cutoff

### Type 2: Timeless Facts (Grounding Optional)

**Query:** "What is the capital of France?"

**Without Grounding:**
```
The capital of France is Paris.
```

**With Grounding:**
```
The capital of France is Paris.
[May or may not include sources - model may not search for well-established facts]
```

**Why grounding doesn't add much value:** Timeless, well-established fact

### Type 3: Recent Specific Events (Grounding Essential)

**Query:** "Who won the Nobel Prize in Physics in 2025?"

**With Grounding:**
```
The 2025 Nobel Prize in Physics was awarded to Dr. Elena Rodriguez and
Dr. Kenji Yamamoto for their groundbreaking work on quantum error correction,
enabling practical quantum computing applications.
[Source: NobelPrize.org, October 2025]
```

**Why grounding helps:** Recent event, specific date, needs authoritative source

### Type 4: Dynamic Data (Grounding Essential)

**Query:** "What is the current stock price of Tesla?"

**With Grounding:**
```
As of January 24, 2026, Tesla (TSLA) is trading at approximately $245.30,
up 2.3% from the previous close.
[Source: Google Finance / Yahoo Finance, Jan 24, 2026]

Note: Stock prices change rapidly. This information may be outdated by
the time you read it.
```

**Why grounding helps:** Real-time data, changes continuously

## When to Use Grounding

| Query Type | Grounding Value | Example |
|------------|-----------------|---------|
| Current events | HIGH | "Latest AI regulations in EU 2026" |
| Recent research | HIGH | "2025 breakthrough in fusion energy" |
| Stock prices / sports scores | HIGH | "Current NASDAQ index" |
| Historical facts | LOW | "Date of French Revolution" |
| Mathematical calculations | LOW | "What is 15% of 240?" |
| Code explanations | LOW | "Explain Python decorators" |
| Product comparisons | MEDIUM | "Compare iPhone 15 vs Samsung S24" |
| Controversial topics | HIGH | Fact-checking with sources |

## API Code (Python)

```python
from google import genai
from google.genai import types

client = genai.Client(api_key="YOUR_API_KEY")

# Enable Google Search grounding
grounding_tool = types.Tool(google_search=types.GoogleSearch())
config = types.GenerateContentConfig(tools=[grounding_tool])

response = client.models.generate_content(
    model="gemini-3-flash-preview",
    contents="What are the latest updates to the Gemini API in January 2026?",
    config=config
)

# Access response text
print("Response:", response.text)

# Access grounding metadata
if response.grounding_metadata:
    print("\nSearch queries used:")
    print(response.grounding_metadata.web_search_queries)

    print("\nSources:")
    for chunk in response.grounding_metadata.grounding_chunks:
        print(f"  - {chunk.web.title}: {chunk.web.uri}")

    # Extract inline citations
    print("\nCitations:")
    for support in response.grounding_metadata.grounding_supports:
        segment = response.text[support.segment.start_index:support.segment.end_index]
        source_indices = support.grounding_chunk_indices
        sources = [response.grounding_metadata.grounding_chunks[i].web.uri for i in source_indices]
        print(f"  Text: '{segment}'")
        print(f"  Sources: {sources}")
```

## Key Learnings

- **Automatic grounding:** Gemini decides whether to search based on query needs
- **Citations included:** Grounded responses include source attribution
- **Metadata structure:** groundingChunks (sources) + groundingSupports (text → source mapping)
- **Not always triggered:** Simple factual queries may not need web search
- **Cost awareness:** Grounding adds cost in production (free in AI Studio for testing)
- **Fact-checking enabled:** Sources allow verification of claims

## Common Issues

**Issue:** "Grounding didn't trigger even though I need current info"
**Solution:** Be more explicit: "What are the latest [thing] as of [current date]?"

**Issue:** "Can't find grounding metadata in UI"
**Solution:** Metadata visibility varies. Use API for full access to grounding structure.

**Issue:** "Response has no citations"
**Solution:** Not all grounded responses include visible citations in text. Check metadata for sources.

**Issue:** "Grounding returned outdated information"
**Solution:** Web search results may vary. Grounding fetches current results but quality depends on available sources.

## Grounding vs RAG Comparison

| Aspect | Manual RAG | Gemini Grounding |
|--------|-----------|------------------|
| Setup complexity | High (build pipeline) | Low (toggle on) |
| Maintenance | Manual updates needed | Automatic |
| Citation extraction | Manual parsing | Built-in metadata |
| Cost | Infrastructure + LLM | LLM + grounding fee |
| Data sources | Your choice | Google Search |
| Specialized data | Supports proprietary | Public web only |

**When to use grounding:** Public web information, current events, fact-checking
**When to use RAG:** Proprietary data, specialized domains, custom data sources

## Real-World Use Cases

- **News summarization:** Get current events with source attribution
- **Research assistance:** Find latest papers, studies, developments
- **Fact-checking:** Verify claims with authoritative sources
- **Market data:** Stock prices, sports scores, weather
- **Documentation:** Keep docs current without manual updates
- **Product comparisons:** Get latest features, pricing, reviews
  </action>
  <verify>
Verify both files exist and contain required sections:

```bash
cat modules/05-grounding-search/exercise.md | grep -E "(Option A:|Step [0-9]:|Success Criteria:)" | wc -l
```
Expected: At least 6 matches

```bash
cat modules/05-grounding-search/solutions/solution.md | grep -E "(Query Type|Grounding Metadata|API Code|Key Learnings|Grounding vs RAG)" | wc -l
```
Expected: At least 5 matches

Verify metadata structure is included:
```bash
cat modules/05-grounding-search/solutions/solution.md | grep -i "groundingChunk\|groundingSupport\|webSearchQueries" | wc -l
```
Expected: At least 6 mentions
  </verify>
  <done>
Exercise file exists with guided challenge testing four query types (current events, facts, Nobel Prize, stock prices), independent option for pattern analysis, and Going Further section. Solution includes complete examples with metadata structure, API code, comparison table for when to use grounding, and Grounding vs RAG comparison showing appropriate use cases.
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

1. Verify directory structure:
   ```bash
   ls -R modules/05-grounding-search/
   ```
   Expected: README.md, demonstration.md, exercise.md, solutions/solution.md

2. Verify grounding metadata is thoroughly explained:
   ```bash
   grep -ri "groundingMetadata\|groundingChunk\|groundingSupport" modules/05-grounding-search/ | wc -l
   ```
   Expected: At least 15 mentions across files

3. Verify pitfall is addressed:
   ```bash
   grep -ri "not.*trigger\|selective\|decides" modules/05-grounding-search/ | wc -l
   ```
   Expected: At least 5 mentions (emphasizing automatic/selective nature)

4. Verify comparison with RAG:
   ```bash
   grep -ri "RAG\|retrieval augmented" modules/05-grounding-search/ | wc -l
   ```
   Expected: At least 3 mentions (positioning grounding as modern alternative)
</verification>

<success_criteria>
Module 05 is complete when:
- [ ] All module files exist with proper structure
- [ ] README explains grounding vs RAG and knowledge cutoff problem
- [ ] Demonstration shows grounding toggle in AI Studio with before/after comparison
- [ ] Exercise includes testing four query types to understand selectivity
- [ ] Solutions include complete grounding metadata structure example
- [ ] Pitfall addressed: grounding is automatic, not triggered for every query
- [ ] API code shows how to enable and extract grounding metadata
- [ ] Comparison table explains when to use grounding vs RAG
- [ ] Duration fits 20-minute target
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-05-SUMMARY.md`
</output>
