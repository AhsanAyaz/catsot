---
phase: 01-foundation
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - modules/03-multimodal-input/README.md
  - modules/03-multimodal-input/demonstration.md
  - modules/03-multimodal-input/exercise.md
  - modules/03-multimodal-input/sample-images/chart.png
  - modules/03-multimodal-input/sample-images/code-screenshot.png
  - modules/03-multimodal-input/sample-images/ui-mockup.png
  - modules/03-multimodal-input/solutions/solution.md
autonomous: true

must_haves:
  truths:
    - "Demonstration shows image upload and multimodal analysis"
    - "Participants can upload images and get text analysis from Gemini"
    - "Sample images are provided and optimized for low token cost"
    - "Exercise covers real-world image analysis use cases"
  artifacts:
    - path: "modules/03-multimodal-input/README.md"
      provides: "Module overview for multimodal input"
      min_lines: 20
    - path: "modules/03-multimodal-input/demonstration.md"
      provides: "Image upload and analysis demonstration"
      min_lines: 40
    - path: "modules/03-multimodal-input/sample-images/chart.png"
      provides: "Sample chart for data extraction demo"
      contains: "placeholder reference"
    - path: "modules/03-multimodal-input/solutions/solution.md"
      provides: "Complete solution with prompts and expected outputs"
      min_lines: 30
  key_links:
    - from: "modules/03-multimodal-input/exercise.md"
      to: "sample-images/"
      via: "references provided images"
      pattern: "sample-images/"
    - from: "modules/03-multimodal-input/demonstration.md"
      to: "AI Studio image upload"
      via: "file upload instructions"
      pattern: "upload.*image"
---

<objective>
Create Module 03: Multimodal Input - teaching participants how to use images as context for Gemini, enabling visual understanding in AI applications.

Purpose: Multimodal capability is a key differentiator for modern LLMs. This module shows practical use cases (chart analysis, code screenshots, UI mockups) and teaches token-efficient image handling.

Output: Complete module with curated sample images, demonstration of image upload workflow, hands-on exercise analyzing different image types, and solutions showing expected analysis quality.
</objective>

<execution_context>
@/home/ahsan/.claude/get-shit-done/workflows/execute-plan.md
@/home/ahsan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@/home/ahsan/projects/code-at-speed-of-thought/.planning/PROJECT.md
@/home/ahsan/projects/code-at-speed-of-thought/.planning/ROADMAP.md
@/home/ahsan/projects/code-at-speed-of-thought/.planning/STATE.md
@/home/ahsan/projects/code-at-speed-of-thought/.planning/phases/01-foundation/01-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Create Module 03 structure, README, and sample image placeholders</name>
  <files>
    modules/03-multimodal-input/README.md
    modules/03-multimodal-input/sample-images/.gitkeep
    modules/03-multimodal-input/sample-images/README.md
    modules/03-multimodal-input/solutions/.gitkeep
  </files>
  <action>
Create module directory structure and README following the established pattern.

**README.md content:**
- Module title: "Module 03: Multimodal Input"
- Duration: 20 minutes
- Learning Objectives:
  * Understand multimodal capabilities of Gemini (vision + language)
  * Upload images to AI Studio for analysis
  * Write effective prompts that combine image and text context
  * Recognize token cost considerations for images
- Prerequisites:
  * Completion of Module 01 (AI Studio basics)
  * Basic understanding of common image use cases
- Overview explaining why multimodal matters (analyze charts, describe UI, explain code screenshots)
- Warning about image token costs with reference to RESEARCH.md findings:
  * Images ≤384px: 258 tokens
  * Larger images: tiled at higher cost
  * Recommendation: use small, optimized images for workshop
- Reference to demonstration.md, exercise.md, and sample-images/

**sample-images/README.md content:**
Create a guide explaining the provided sample images and their intended use cases:

```markdown
# Sample Images for Module 03

These images are optimized for workshop use (≤384px to minimize token cost).

## Provided Images

### 1. chart.png
**Use case:** Data extraction and analysis
**Prompt ideas:**
- "What data does this chart show?"
- "Summarize the key trends"
- "Extract the data as JSON"

### 2. code-screenshot.png
**Use case:** Code explanation and review
**Prompt ideas:**
- "Explain what this code does"
- "Identify potential bugs"
- "Suggest improvements"

### 3. ui-mockup.png
**Use case:** Design analysis and description
**Prompt ideas:**
- "Describe this user interface"
- "What improvements would you suggest?"
- "Write alt text for accessibility"

## Creating Your Own Images

For workshop exercises, keep images small:
- Maximum dimension: 384px
- File format: PNG or JPEG
- File size: <100KB recommended

Larger images consume more tokens (see RESEARCH.md for details).
```

Create placeholder references for the three image files (actual images would be provided by user or created separately):
- chart.png (placeholder note: "Sample chart showing data trends")
- code-screenshot.png (placeholder note: "Screenshot of Python/JavaScript code")
- ui-mockup.png (placeholder note: "Wireframe or UI design mockup")
  </action>
  <verify>
Verify files exist:
```bash
ls -R modules/03-multimodal-input/
```
Expected: README.md, sample-images/README.md, sample-images/.gitkeep, solutions/.gitkeep

Verify README has token cost warning:
```bash
cat modules/03-multimodal-input/README.md | grep -i "token" | wc -l
```
Expected: At least 2 mentions

Verify sample-images README explains use cases:
```bash
cat modules/03-multimodal-input/sample-images/README.md | grep -E "(Use case:|Prompt ideas:)" | wc -l
```
Expected: At least 6 matches (3 images × 2 sections each)
  </verify>
  <done>
Module 03 structure exists with README containing learning objectives and token cost warnings, sample-images directory with README explaining three use cases (chart, code, UI), and placeholders for image files.
  </done>
</task>

<task type="auto">
  <name>Create demonstration showing image upload and multimodal prompting</name>
  <files>modules/03-multimodal-input/demonstration.md</files>
  <action>
Create the instructor demonstration guide showing AI Studio's image upload feature and multimodal prompting patterns.

**Content structure (5-7 minute demonstration):**

**Introduction (1 minute):**
- What is multimodal input (combining images + text)
- Why it matters: analyze visuals, understand context, extract data from images
- Gemini is natively multimodal (no separate vision API needed)

**Step-by-step demonstration (5-6 minutes):**

1. **Prepare for image upload**
   - Action: Open AI Studio, create new prompt
   - Action: Locate the upload button (usually a paperclip or image icon)
   - Point out: Can upload multiple images in one prompt

2. **Upload first image (chart example)**
   - Action: Click upload, select `sample-images/chart.png`
   - Expected result: Image preview appears in prompt editor
   - [Screenshot: Image uploaded in AI Studio]

3. **Write multimodal prompt**
   - Action: Below the image, enter prompt: "What data does this chart show? Summarize the key findings."
   - Expected result: Prompt combines image + text
   - Point out: No special syntax needed, just natural language
   - Action: Click "Run"
   - Expected result: Gemini analyzes image and provides data summary
   - [Screenshot: Response describing chart data]

4. **Demonstrate structured extraction**
   - Action: Keep same image, change prompt: "Extract the data from this chart as JSON with format: {labels: [], values: []}"
   - Action: Run
   - Expected result: JSON output with chart data
   - Point out: Combines multimodal (image) + structured output (from Module 02)

5. **Show code screenshot analysis**
   - Action: Remove chart, upload `sample-images/code-screenshot.png`
   - Action: Prompt: "Explain what this code does in simple terms"
   - Action: Run
   - Expected result: Code explanation
   - Try follow-up: "Are there any potential bugs?"
   - Expected result: Bug analysis
   - Point out: Useful for code review, documentation, learning

6. **Discuss token costs**
   - Show: Token usage indicator after image prompt
   - Explain: Images ≤384px = 258 tokens, larger images = more (tiled)
   - Recommend: For workshop/testing, use small optimized images
   - Show: File API approach for production (mentioned in RESEARCH.md)

**Key talking points:**
- **Natively multimodal:** No separate vision API, same model handles text + images
- **Natural language:** No special prompting syntax for images
- **Combinable:** Use with structured output, system instructions, etc.
- **Token awareness:** Larger images = higher cost, optimize for production
- **Multiple images:** Can upload several images in one prompt (e.g., before/after)

**Live demonstration tip:**
Use actual sample images to show real responses, not just describe the process.
  </action>
  <verify>
Verify demonstration.md exists and contains:
- Introduction explaining multimodal concept
- 6 numbered steps with Action/Expected result pairs
- At least 2 screenshot placeholders
- Token cost discussion section
- Key talking points

```bash
cat modules/03-multimodal-input/demonstration.md | grep -E "(Action:|Expected result:|Screenshot:|token)" | wc -l
```
Expected: At least 15 matches
  </verify>
  <done>
Demonstration guide exists with complete walkthrough of image upload, multimodal prompting for three use cases (chart, code, UI), structured extraction example, and token cost discussion following RESEARCH.md guidance.
  </done>
</task>

<task type="auto">
  <name>Create hands-on exercise with multiple image analysis tasks</name>
  <files>
    modules/03-multimodal-input/exercise.md
    modules/03-multimodal-input/solutions/solution.md
  </files>
  <action>
Create the hands-on exercise where participants practice multimodal analysis with different image types.

**exercise.md content (10-13 minutes):**

**Your Task:**
Practice multimodal input by analyzing different types of images with Gemini.

**Setup (1 minute):**
1. Open aistudio.google.com
2. Create a new prompt
3. Locate the image upload button

**Option A: Guided Challenge (For beginners)**

**Challenge:** Analyze the three provided sample images

Step 1: Chart analysis (3 minutes)
- Upload `sample-images/chart.png`
- Prompt: "What data does this chart show? Summarize the key trends."
- Click Run and observe response
- Try follow-up: "Extract this data as a JSON array"
- Success criteria: You get a text summary and structured data

Step 2: Code screenshot analysis (3 minutes)
- Remove chart, upload `sample-images/code-screenshot.png`
- Prompt: "Explain what this code does step by step"
- Click Run
- Try follow-up: "Are there any bugs or improvements you'd suggest?"
- Success criteria: You get code explanation and review feedback

Step 3: UI mockup analysis (3 minutes)
- Remove code, upload `sample-images/ui-mockup.png`
- Prompt: "Describe this user interface. What is its purpose?"
- Click Run
- Try follow-up: "Suggest 3 improvements to this design"
- Success criteria: You get design description and suggestions

Step 4: Check token usage (1 minute)
- Observe token usage for each image prompt
- Note: Small images (≤384px) use ~258 tokens
- Experiment: What happens with larger images? (optional)

**Option B: Independent Challenge (For advanced users)**

Goal: Upload your own image or use a provided sample, then extract meaningful insights using multimodal prompts.

Task ideas:
- Analyze a data visualization and extract the data as structured JSON
- Review a code screenshot and generate documentation
- Describe a UI design and generate HTML/CSS to implement it
- Compare two images (before/after, option A vs B)

Requirements:
- Use at least 2 different images
- Write prompts that extract specific information (not just "describe this")
- Try combining multimodal with structured output (JSON schema)
- Check token usage and optimize if needed

Solution: See `solutions/solution.md` for reference approaches

**For Fast Finishers: Going Further**

Advanced challenges:
- Upload multiple images in one prompt (e.g., "Compare these two charts")
- Combine image + text context (e.g., image of diagram + explanation text)
- Use structured output schema for consistent image analysis results
- Try different image types: diagrams, photos, screenshots, art
- Experiment with the File API approach (see RESEARCH.md code examples)

**Success Criteria:**
- [ ] You have uploaded and analyzed at least 2 different images
- [ ] You understand that Gemini can "see" and describe visual content
- [ ] You have tried both descriptive and extractive prompts
- [ ] You are aware of token costs for images
- [ ] You can imagine multimodal use cases for your projects

Duration: ⏱️ Expected: 11 minutes | Buffer: 3 minutes

**solutions/solution.md content:**

# Module 03 Solution

## Chart Analysis Example

**Image:** sample-images/chart.png (bar chart showing quarterly revenue)

**Prompt 1 (Descriptive):**
```
What data does this chart show? Summarize the key trends.
```

**Expected Response:**
```
This bar chart shows quarterly revenue over four quarters (Q1-Q4). Key trends:
- Revenue increased from Q1 ($50K) to Q3 ($85K)
- Q4 shows a slight decline to $78K
- Overall trend is positive growth with a minor dip at year-end
- Strongest performance in Q3
```

**Prompt 2 (Extractive with structure):**
```
Extract the data from this chart as JSON with this format:
{
  "quarters": ["Q1", "Q2", ...],
  "revenue": [50000, ...]
}
```

**Expected Response:**
```json
{
  "quarters": ["Q1", "Q2", "Q3", "Q4"],
  "revenue": [50000, 68000, 85000, 78000]
}
```

## Code Screenshot Analysis Example

**Image:** sample-images/code-screenshot.png (Python function)

**Prompt:**
```
Explain what this code does step by step. Then identify any potential bugs or improvements.
```

**Expected Response:**
```
This code defines a function `calculate_discount` that:
1. Takes price and customer_type as parameters
2. Applies different discount rates based on customer type
3. Returns the discounted price

Potential improvements:
- Add input validation (check if price is positive)
- Use a dictionary for discount rates instead of if/elif chain
- Add docstring explaining parameters and return value
- Handle edge case if customer_type is not recognized (currently returns full price)

Improved version:
DISCOUNT_RATES = {
    'premium': 0.20,
    'regular': 0.10,
    'new': 0.05
}

def calculate_discount(price: float, customer_type: str) -> float:
    """Calculate discounted price based on customer type."""
    if price < 0:
        raise ValueError("Price must be positive")
    discount_rate = DISCOUNT_RATES.get(customer_type, 0)
    return price * (1 - discount_rate)
```

## UI Mockup Analysis Example

**Image:** sample-images/ui-mockup.png (mobile app wireframe)

**Prompt:**
```
Describe this user interface. What is its purpose? Suggest 3 improvements.
```

**Expected Response:**
```
This is a mobile app login screen with:
- App logo at top
- Email and password input fields
- "Login" button
- "Forgot password?" link
- "Sign up" link at bottom

Purpose: User authentication for the app

Suggested improvements:
1. Add social login options (Google, Apple) for faster signup
2. Include password visibility toggle (eye icon) for better UX
3. Add loading state indicator for the login button
4. Consider biometric authentication option (fingerprint/face ID)
5. Improve accessibility with larger touch targets and better contrast
```

## API Code for Multimodal (Python)

```python
from google import genai
from google.genai import types
import pathlib

client = genai.Client(api_key="YOUR_API_KEY")

# Upload image using File API (recommended for reuse)
image_file = client.files.upload(
    path=pathlib.Path("sample-images/chart.png")
)

# Multimodal prompt with image + text
response = client.models.generate_content(
    model="gemini-3-flash-preview",
    contents=[
        types.Part.from_uri(
            file_uri=image_file.uri,
            mime_type=image_file.mime_type
        ),
        "Extract the data from this chart as JSON"
    ]
)

print(response.text)
```

## Key Learnings

- **Natively multimodal:** Same Gemini model handles images and text together
- **No special syntax:** Upload image, write natural language prompt
- **Combinable features:** Multimodal + structured output + system instructions work together
- **Token costs matter:** Images ≤384px = 258 tokens, larger = more (tiled)
- **File API for production:** Upload once, reuse across prompts (saves tokens)
- **Multiple images:** Can upload several in one prompt for comparison

## Common Issues

**Issue:** "Image upload not working"
**Solution:** Check file format (PNG, JPEG supported), size (<10MB), try refreshing AI Studio

**Issue:** "Response doesn't describe image accurately"
**Solution:** Be more specific in prompt. Instead of "describe this", ask "What data is shown in this chart?" or "What UI elements are visible?"

**Issue:** "Token usage is very high"
**Solution:** Resize image to ≤384px before upload. Large images are tiled and consume more tokens.

**Issue:** "Can I use video?"
**Solution:** Gemini supports video input via API, but AI Studio (as of 2026) primarily supports images. Check documentation for latest capabilities.

## Real-World Use Cases

- **Data extraction:** Convert charts/graphs to structured data
- **Code documentation:** Generate explanations from code screenshots
- **UI/UX review:** Analyze designs and suggest improvements
- **Accessibility:** Generate alt text for images
- **Content moderation:** Analyze images for safety/policy compliance
- **Receipt parsing:** Extract data from photos of receipts/invoices
- **Diagram understanding:** Explain technical diagrams or flowcharts
  </action>
  <verify>
Verify both files exist and contain required sections:

```bash
cat modules/03-multimodal-input/exercise.md | grep -E "(Option A:|Option B:|Step [0-9]:|Success Criteria:)" | wc -l
```
Expected: At least 6 matches

```bash
cat modules/03-multimodal-input/solutions/solution.md | grep -E "(Example|Prompt|Expected Response|API Code|Key Learnings)" | wc -l
```
Expected: At least 7 matches

Verify solution includes real-world use cases:
```bash
cat modules/03-multimodal-input/solutions/solution.md | grep -i "use case" | wc -l
```
Expected: At least 5 mentions
  </verify>
  <done>
Exercise file exists with guided path covering chart, code, and UI analysis, independent option for custom image exploration, and Going Further section. Solution includes complete examples for all three image types, API code, key learnings about token costs, and real-world use cases showing practical applications.
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

1. Verify directory structure:
   ```bash
   ls -R modules/03-multimodal-input/
   ```
   Expected: README.md, demonstration.md, exercise.md, sample-images/README.md, solutions/solution.md

2. Verify sample images documentation:
   ```bash
   cat modules/03-multimodal-input/sample-images/README.md | grep "Use case" | wc -l
   ```
   Expected: At least 3 (one per sample image)

3. Verify token cost awareness:
   ```bash
   grep -ri "token" modules/03-multimodal-input/ | wc -l
   ```
   Expected: At least 10 mentions across all files

4. Verify multimodal + structured output combination is demonstrated:
   ```bash
   grep -ri "JSON" modules/03-multimodal-input/ | wc -l
   ```
   Expected: At least 5 mentions (combining Module 02 and 03 concepts)
</verification>

<success_criteria>
Module 03 is complete when:
- [ ] All module files exist with proper structure
- [ ] Sample images directory with README explaining three use cases
- [ ] Demonstration shows image upload workflow in AI Studio
- [ ] Exercise covers chart, code, and UI analysis tasks
- [ ] Solutions include expected responses for all three image types
- [ ] Token cost awareness is prominent (images ≤384px recommendation)
- [ ] Multimodal + structured output combination is demonstrated
- [ ] Real-world use cases listed in solutions
- [ ] Duration fits 20-minute target
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-03-SUMMARY.md`
</output>
