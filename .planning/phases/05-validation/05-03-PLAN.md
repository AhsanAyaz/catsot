---
phase: 05-validation
plan: 03
type: execute
wave: 3
depends_on: ["05-02"]
files_modified:
  - .planning/phases/05-validation/DRY-RUN-LOG.md
  - .planning/phases/05-validation/TIMING-LOG.md
  - .planning/phases/05-validation/VALIDATION-CHECKLIST.md
autonomous: false

must_haves:
  truths:
    - "Part 1 modules fit within 2-hour target with 15-minute buffer"
    - "Part 2 projects fit within 1.5-hour target"
    - "LEARN-01: Context engineering concepts are clear (self-assessment passes)"
    - "LEARN-02: Structured output concepts are clear (self-assessment passes)"
    - "LEARN-03: Multimodal input concepts are clear (self-assessment passes)"
    - "LEARN-04: MediaPipe integration is achievable (self-assessment passes)"
    - "DELIV-01: Firebase deployment produces shareable URL"
    - "DELIV-02: Showcase format works for demos"
    - "DELIV-03: Code export from Firebase Studio works"
  artifacts:
    - path: ".planning/phases/05-validation/DRY-RUN-LOG.md"
      provides: "Complete record of dry-run findings and fixes"
    - path: ".planning/phases/05-validation/TIMING-LOG.md"
      provides: "Section-by-section timing data"
    - path: ".planning/phases/05-validation/VALIDATION-CHECKLIST.md"
      provides: "Completed validation checklist"
  key_links:
    - from: "DRY-RUN-LOG.md"
      to: "modules/*/demonstration.md"
      via: "issue references"
      pattern: "modules/[0-9]+-"
---

<objective>
Execute the workshop dry-run: walk through all content section-by-section, validate timing, confirm learning outcomes via self-assessment, test deployment flow, and fix issues as found.

Purpose: This is the final validation before the January 28, 2026 workshop. Ensures all materials work in practice, timing fits schedule, and learning outcomes are achievable.

Output: Completed validation documents (timing log, dry-run log, validation checklist) and any fixes applied during the run.
</objective>

<execution_context>
@/home/ahsan/.claude/get-shit-done/workflows/execute-plan.md
@/home/ahsan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-validation/05-CONTEXT.md
@.planning/phases/05-validation/05-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create dry-run validation templates</name>
  <files>
    .planning/phases/05-validation/DRY-RUN-LOG.md
    .planning/phases/05-validation/TIMING-LOG.md
    .planning/phases/05-validation/VALIDATION-CHECKLIST.md
  </files>
  <action>
    Create three validation documents to be used during the dry-run:

    **1. TIMING-LOG.md**
    Template with sections for:
    - Part 1 modules (01-06) with target times and actual time columns
    - Part 2 project with phases (setup, implementation, extensions, deployment)
    - Showcase simulation
    - Running total and variance tracking
    - Notes column for timing observations

    Structure per section:
    ```
    ## Module 01: AI Studio Exploration
    | Section | Target | Actual | Variance | Notes |
    |---------|--------|--------|----------|-------|
    | Demo walkthrough | 5-7 min | | | |
    | Exercise | 8-10 min | | | |
    | Going Further | 3-5 min | | | |
    | **Total** | **20 min** | | | |

    Self-assessment: Could I explain AI Studio basics? [ ]
    ```

    **2. DRY-RUN-LOG.md**
    Template for recording issues:
    - Date/time
    - Location (module, file, line)
    - Issue description
    - Resolution (fixed/deferred/note)
    - Time spent on fix

    **3. VALIDATION-CHECKLIST.md**
    Comprehensive checklist covering all success criteria:

    ### Technical Verification
    - [ ] AI Studio interface matches documentation
    - [ ] Model names work in code examples
    - [ ] Code examples run without errors
    - [ ] Grounding toggle produces expected behavior
    - [ ] MediaPipe loads correctly in Part 2 projects
    - [ ] Firebase emulator works

    ### Learning Outcomes (self-assessment)
    - [ ] LEARN-01: Context engineering understanding (after Module 04)
    - [ ] LEARN-02: Structured output understanding (after Module 02)
    - [ ] LEARN-03: Multimodal input understanding (after Module 03)
    - [ ] LEARN-04: MediaPipe integration (after Part 2)

    ### Delivery Requirements
    - [ ] DELIV-01: Firebase deployment produces shareable URL
    - [ ] DELIV-02: Showcase format tested (3-4 demo simulation)
    - [ ] DELIV-03: Code export from Firebase Studio works

    ### Timing Validation
    - [ ] Part 1 fits in 2 hours (with 15-min buffer)
    - [ ] Part 2 fits in 1.5 hours
    - [ ] Trimmable sections identified if needed

    ### Cross-Reference Validation
    - [ ] Slide references to modules work
    - [ ] Cheatsheet references work
    - [ ] Quick Reference sections accurate
  </action>
  <verify>
    Run: `ls .planning/phases/05-validation/*.md | grep -E "(DRY-RUN|TIMING|VALIDATION)" | wc -l` returns 3
    Run: `grep -c "LEARN-0" .planning/phases/05-validation/VALIDATION-CHECKLIST.md` returns 4
    Run: `grep -c "DELIV-0" .planning/phases/05-validation/VALIDATION-CHECKLIST.md` returns 3
  </verify>
  <done>Validation templates created and ready for dry-run.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Dry-run validation framework with timing log, issue log, and comprehensive checklist</what-built>
  <how-to-verify>
    **This is the dry-run checkpoint. You will walk through the entire workshop.**

    **Before starting:**
    1. Open `.planning/phases/05-validation/TIMING-LOG.md` to record times
    2. Open `.planning/phases/05-validation/DRY-RUN-LOG.md` for issues
    3. Have a stopwatch ready
    4. Use an incognito browser window for fresh state

    **Part 1 Dry-run (Target: 2 hours)**

    Walk through each module in order:
    1. **Module 01**: AI Studio Exploration (~20 min)
       - Read demonstration.md, do the exercise
       - Self-assessment: "Could I explain AI Studio basics?"
       - Record time in TIMING-LOG.md

    2. **Module 02**: Structured Output (~20 min)
       - Self-assessment: "Could I explain JSON schemas for output?"
       - Record time

    3. **Module 03**: Multimodal Input (~20 min)
       - Test sample images work
       - Self-assessment: "Could I explain image analysis with Gemini?"
       - Record time

    4. **Module 04**: Context Engineering (~20 min)
       - Self-assessment: "Could I explain system instructions and few-shot prompting?"
       - Record time

    5. **Module 05**: Grounding with Search (~15 min) *trimmable*
       - Self-assessment: "Could I explain when to use grounding?"
       - Record time

    6. **Module 06**: Logic Engine (~25 min)
       - Self-assessment: "Could I explain vibe coding with AI?"
       - Record time

    **Part 2 Dry-run (Target: 1.5 hours)**

    Choose one project path (face-reactive recommended):
    1. Project setup (~10 min)
    2. Core implementation (~45 min)
    3. Extension challenges (~20 min) *trimmable*
    4. Firebase deployment (~15 min)
       - Verify shareable URL works

    **Showcase Simulation (~10 min)**
    - Practice demo presentation format
    - Test screen sharing

    **Fix-as-you-go:**
    - If you find an issue, log it and fix immediately
    - Note time spent on fixes

    **When complete:**
    1. Fill in VALIDATION-CHECKLIST.md
    2. Summarize findings
    3. Type "dry-run complete" with summary
  </how-to-verify>
  <resume-signal>Type "dry-run complete" with summary of timing and issues found</resume-signal>
</task>

<task type="auto">
  <name>Task 3: Finalize validation documents</name>
  <files>
    .planning/phases/05-validation/DRY-RUN-LOG.md
    .planning/phases/05-validation/TIMING-LOG.md
    .planning/phases/05-validation/VALIDATION-CHECKLIST.md
  </files>
  <action>
    Based on user's dry-run feedback, finalize the validation documents:

    1. **TIMING-LOG.md**
       - Ensure all times are recorded
       - Calculate totals and variance from targets
       - Add summary section with:
         - Part 1 total vs 2-hour target
         - Part 2 total vs 1.5-hour target
         - Buffer usage
         - Recommendations for timing adjustments

    2. **DRY-RUN-LOG.md**
       - Ensure all issues are documented
       - Mark resolution status (fixed/deferred/noted)
       - Add summary section with:
         - Total issues found
         - Issues fixed during dry-run
         - Outstanding items (if any)

    3. **VALIDATION-CHECKLIST.md**
       - Ensure all checkboxes are marked
       - Add completion date
       - Add final status: PASSED / PASSED WITH NOTES / NEEDS ATTENTION

    Create a final summary section in each document.
  </action>
  <verify>
    Run: `grep -c "\[x\]" .planning/phases/05-validation/VALIDATION-CHECKLIST.md` shows completed items
    Run: `grep "status:" .planning/phases/05-validation/VALIDATION-CHECKLIST.md` shows final status
  </verify>
  <done>All validation documents finalized with dry-run results.</done>
</task>

</tasks>

<verification>
1. Timing validated: TIMING-LOG.md shows Part 1 under 2 hours, Part 2 under 1.5 hours
2. Learning outcomes verified: All LEARN-* items checked in VALIDATION-CHECKLIST.md
3. Delivery requirements met: All DELIV-* items checked in VALIDATION-CHECKLIST.md
4. Issues documented: DRY-RUN-LOG.md contains any issues found with resolution status
</verification>

<success_criteria>
1. Dry-run completed with timing data recorded
2. All learning outcome self-assessments pass
3. All delivery requirements verified
4. Validation documents finalized with clear status
5. Workshop ready for January 28, 2026 delivery
</success_criteria>

<output>
After completion, create `.planning/phases/05-validation/05-03-SUMMARY.md`
</output>
